[{"id":0,"href":"/cs7210/lectures/lecture03/","title":"03 Time in Distributed Systems","parent":"Lectures","content":"Introduction     Distributed Systems cannot rely on Physical Clocks so they rely on Logical Clocks  Why Do We Need Time     There are many scenarios in which knowing the time can be helpful. For eg. checking the correctness of the program. Same operations executed in different  Determining the order of operations executing in the system Checking correctness of the final state with the expected final state    Why Is Measuring Time Hard in DS?     Option 1: Why can\u0026rsquo;t we use local clock on each node to record the time  Good: Since each message is timestamped, there is a global order of all the events Bad: It\u0026rsquo;s impossible to precisely synchronise all the local clocks   Option 2: Let there be a receiver/observer node. Every node in the system sends it a message when an event occurs on that node.  Due to unpredictable delays, message can arrive at the observer out of order Different Observers can report different order of events    Logical Time     Logical clocks, unlike physical clocks, progress only when an event occurs and usually provides a distinct timestamp to each event. Types of clocks (details left out in lecture)  Scalar Clock / Lamport Clocks Vector Clocks Matrix Clocks    Common Notation     There are three type of events : send of a msg, recv of a msg and internal events in a node Note that when a msg is send from node n1 to node n2, two events occur : n1 registers send(msg) event while n2 registers recv(msg) event. e1 → e2 implies, e1 \u0026ldquo;happened before\u0026rdquo; e2 All events on a single node are ordered If a node receives a msg (e1) and sends it (e2) , then e1 → e2 If a node sends a msg (e1) and it is recvd by another node(e2), then e1 → e2  Concurrent Events     If e1 and e2 are not related by \u0026ldquo;happened before\u0026rdquo; relationship, we call them concurrent. Is means that we cannot conclusively state the order in which those events occurred. e1 || e2  Logical Clocks     Timestamps generated by logical clocks need to guarantee some properties to be useful Clock Consistency Condition  e1 → e2 then, C(e1) \u0026lt; C(e2) Monotonicity property, logical clocks must always increase Note that C(e1) \u0026lt; C(e2) does not imply e1 → e2   e1 || e2 then, C(e1) ?? C(e2)  For concurrent events, there are no guarantees, the logical timestamps can be in any order or they may simply be uncomparable   Strong Clock Consistency (not mandatory for all logical clocks)  e1 → e2 ⇔ C(e1) \u0026lt; C(e2)   A logical clock defines a set of rules on how to advance it and how to compare two timestamps.  Lamport\u0026rsquo;s Scalar Clock     Each process had it\u0026rsquo;s own local logical clock Rules  Vector Clocks (vt)      Lamport Clock does not satisfy the Strong Clock Consistency\n  Size of clock is equal to number of processes in the system\n  If vt is the vector clock at a process, then vt[i] represents that process\u0026rsquo;s view of time of ith process.\n  Rules   Comparison Rules\n  Matrix Clocks     Each process maintain N x N matrix Consider process Pi,  i-th row of matrix corresponds to Pi\u0026rsquo;s own vector clock j-th row (other than i) corresponds to Pi\u0026rsquo;s view of Pj \u0026rsquo;s vector clock   Benefits  A process can know if the vector clock of every other process has progressed past a certain time, t. This can be used to delete any data which is cached for processed which are falling behind.    "},{"id":1,"href":"/cs7210/lectures/lecture06/","title":"06 Replication","parent":"Lectures","content":"Goals of Replication     State available at more than one node =\u0026gt; Fault-tolerance, Availability Service can be provided from more than one node =\u0026gt; Scalability  Replication Modes     Active Replication (all replicas read, write and update each other) Stand-by (Primary-backup) Replication (Only one replica reads and writes, rest just follow updates from primary)  Replication Techniques       State Replication Replicated State Machine     Change in state is sent to other replicas The operation (event) is executed(applied) to every replica   + No need to execute operation again + No need to transmit large state delta   - Determining change in state can be complex and large - Operation needs to be executed and must be deterministic    Replication and Consensus    \u0026hellip;\nChain Replication     Lag in replication increases linearly with number of replicas Another option (van Renesse, Schneider, OSDI'14) is to do a synchronous replication.  "},{"id":2,"href":"/cs7210/lectures/lecture07/","title":"07 Fault Tolerance","parent":"Lectures","content":"Fault Tolerance    Some Taxonomy     Fault-Error-Failure  Fault is the problem (software bug, hardware failure) When fault is activated (because buggy part of code is executed), it causes errors Failure is the resulting behaviour   Faults: Transient / Intermittent / Permanent Failures: Fail-stop / Timing / Omission / Byzantine  Timing: System becomes \u0026ldquo;slow\u0026rdquo; Omission: some actions are missing like msg drops due to memory constraints   Managing Failures: Avoidance / Detection / Recovery / Removal  Detected failues are either removed by rollback or recovered from.    Rollback-Recovery     Rollback the system to a state before the failure Rolledback state may not be a real past state. It just needs to be consistent.  Basic Mechanisms     Checkpointing: Save the (full or incremental) state periodically Logging: Log individual write operations.  Undo Log: Log includes original values of variables. This makes it possible to undo an operation. System state can move backward. Redo Log: Log includes new values. To obtain a state, start from beginning and keep applying operations. System state can move forward.    Checkpointing Approaches    System Model\n Network is non-partitionable. Why ?? FIFO / communication channel reliability and num of failures will vary with protocol.  Uncoordinated Approach\n Processes take checkpoints independently. Problems  The failed node rollbacks to previous checkpoint. If the state of the whole system becomes inconsistent, more rollbacks may have to be performed at several nodes =\u0026gt; Domino effect. Leads to multiple useless checkpoints.    Coordinated Checkpoint\n Processes coordinate to take a consistent snapshot. Problems  How to coordinate? No synchronous clock guarantee ie no global clock. (Everybody take snapshot at 5pm) If msg delivery was reliable with bounded delay, some approach could be created.    Communication induced Checkpoint\n Use a consensus protocol: All nodes should reach a consensus that a snapshot will be taken and that they will not send any msg till it\u0026rsquo;s complete. In a way, it\u0026rsquo;s a blocking protocol. A non-blocking algo will be similar to Global Snapshot algo but it requires FIFO communication channel.  Logging\n When reconstructing state we must ensure that it\u0026rsquo;s not a inconsistent state. A crashed process might not log the last event it sent. We might apply events in wrong order. Pessimistic: First log the event then send it. Optimistic: Assume log will be persisted but make it possible to remove it\u0026rsquo;s effect if aborted Causalty-tracking: ensure causality related events are deterministically recorded  Which Method to Use?\n Workload characteristics: Frequency of updatss, size of updates, Failures characteristics: System Characteristics: cost of communication/stoage, system scale,  "},{"id":3,"href":"/","title":"CS7210 - Distributed Computing","parent":"","content":""},{"id":4,"href":"/cs7210/","title":"CS7210 - Distributed Computing","parent":"CS7210 - Distributed Computing","content":"    Labs     DSLabs Abstract Interface     Message Wrappers     WIP       Lectures     03 Time in Distributed Systems     06 Replication     07 Fault Tolerance       "},{"id":5,"href":"/cs7210/labs/01_framework_abstraction/","title":"DSLabs Abstract Interface","parent":"Labs","content":" The system consists of a number of nodes which have addresses A Node can send() a message to another node. The receiving node has to handle() the message. Some nodes expose a client interface. An external user can interact with the distributed system by send()ing commandsand gettting results back. Application: Some nodes (server nodes) have contain an application object. An example of an application would be key-value in-memory store. Application is what the users of the distributed system want to access. An application takes a command as input and produces result as output. Communication is one way i.e. when a node is sending a message, it is not expecting a reply message. Request/Response semantics are implemented at client-server level.  "},{"id":6,"href":"/cs7210/labs/","title":"Labs","parent":"CS7210 - Distributed Computing","content":"    DSLabs Abstract Interface     Message Wrappers     WIP     "},{"id":7,"href":"/cs7210/lectures/","title":"Lectures","parent":"CS7210 - Distributed Computing","content":"    03 Time in Distributed Systems     06 Replication     07 Fault Tolerance     "},{"id":8,"href":"/cs7210/labs/02_packets/","title":"Message Wrappers","parent":"Labs","content":"There are my abstractions:\n Message Requst and Reply MessageEnvelop Command and Result  "},{"id":9,"href":"/tags/","title":"Tags","parent":"CS7210 - Distributed Computing","content":""},{"id":10,"href":"/cs7210/labs/dslabs_client_to_server_communication/","title":"WIP","parent":"Labs","content":""}]